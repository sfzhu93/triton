diff --git a/include/triton/Dialect/TritonGPU/Transforms/PipelineExpander.h b/include/triton/Dialect/TritonGPU/Transforms/PipelineExpander.h
index 0a3d736c6..88871bca0 100644
--- a/include/triton/Dialect/TritonGPU/Transforms/PipelineExpander.h
+++ b/include/triton/Dialect/TritonGPU/Transforms/PipelineExpander.h
@@ -57,6 +57,10 @@ struct PipeliningOption {
   /// pipeliner will have to predicate operations in the the prologue/epilogue.
   bool supportDynamicLoops = false;
 
+  /// The number of stages to use for the pipelining. Generally, it comes from
+  /// ``tt.num_stages``.
+  int numStages = 0;
+
   // Callback to predicate operations when the prologue or epilogue are not
   // peeled. This takes the original operation, an i1 predicate value and the
   // pattern rewriter. It is expected to replace the given operation with
diff --git a/lib/Dialect/TritonGPU/Transforms/Pipeliner/MatmulLoopPipeline.cpp b/lib/Dialect/TritonGPU/Transforms/Pipeliner/MatmulLoopPipeline.cpp
index 5cc537d5f..ea4e63e54 100644
--- a/lib/Dialect/TritonGPU/Transforms/Pipeliner/MatmulLoopPipeline.cpp
+++ b/lib/Dialect/TritonGPU/Transforms/Pipeliner/MatmulLoopPipeline.cpp
@@ -1119,6 +1119,7 @@ bool mlir::triton::preProcessLoopAndGetSchedule(
   options.peelEpilogue = false;
   options.predicateFn = tt::predicateOp;
   options.supportDynamicLoops = true;
+  options.numStages = numStages;
   options.annotateFn = [](Operation *op,
                           mlir::triton::PipeliningOption::PipelinerPart part,
                           unsigned iteration) {};
diff --git a/lib/Dialect/TritonGPU/Transforms/Pipeliner/PipelineExpander.cpp b/lib/Dialect/TritonGPU/Transforms/Pipeliner/PipelineExpander.cpp
index 2f186e3c5..eb8907538 100644
--- a/lib/Dialect/TritonGPU/Transforms/Pipeliner/PipelineExpander.cpp
+++ b/lib/Dialect/TritonGPU/Transforms/Pipeliner/PipelineExpander.cpp
@@ -24,12 +24,16 @@
 #include "mlir/Dialect/SCF/IR/SCF.h"
 #include "mlir/Dialect/SCF/Transforms/Patterns.h"
 #include "mlir/Dialect/SCF/Utils/Utils.h"
+#include "mlir/IR/BuiltinAttributes.h"
 #include "mlir/IR/IRMapping.h"
 #include "mlir/IR/PatternMatch.h"
+#include "mlir/Support/LLVM.h"
 #include "mlir/Transforms/RegionUtils.h"
 #include "llvm/ADT/MapVector.h"
 #include "llvm/Support/Debug.h"
 #include "llvm/Support/MathExtras.h"
+#include <cstdint>
+#include <optional>
 
 #include "triton/Dialect/TritonGPU/Transforms/PipelineExpander.h"
 
@@ -37,6 +41,10 @@
 #define DBGS() (llvm::dbgs() << "[" DEBUG_TYPE "]: ")
 #define LDBG(X) LLVM_DEBUG(DBGS() << X << "\n")
 
+#define PERF_WARNING(OP, INFO)                                                 \
+  (OP).emitRemark() << "Warning: " << INFO << ".\n"                            \
+                    << "Performance is possibly impacted.\n"
+
 using namespace mlir;
 using namespace mlir::scf;
 using namespace mlir::triton;
@@ -114,29 +122,47 @@ bool LoopPipelinerInternal::initializeLoopInfo(
     ForOp op, const triton::PipeliningOption &options) {
   LDBG("Start initializeLoopInfo");
   forOp = op;
+
   ub = forOp.getUpperBound();
   lb = forOp.getLowerBound();
   step = forOp.getStep();
 
   dynamicLoop = true;
-  auto upperBoundCst = ub.getDefiningOp<arith::ConstantIndexOp>();
-  auto lowerBoundCst = lb.getDefiningOp<arith::ConstantIndexOp>();
-  auto stepCst = step.getDefiningOp<arith::ConstantIndexOp>();
+
+  auto getIntegerAttrFromValue =
+      [](mlir::Value value) -> std::optional<mlir::IntegerAttr> {
+    auto constantOp = value.getDefiningOp<arith::ConstantOp>();
+    if (!constantOp) {
+      // Not defined by a ConstantOp
+      return std::nullopt;
+    }
+    // return constantOp.getValue().dyn_cast<mlir::IntegerAttr>();
+    return mlir::cast<mlir::IntegerAttr>(constantOp.getValue());
+  };
+  auto upperBoundCst = getIntegerAttrFromValue(ub);
+  auto lowerBoundCst = getIntegerAttrFromValue(lb);
+  auto stepCst = getIntegerAttrFromValue(step);
   if (!upperBoundCst || !lowerBoundCst || !stepCst) {
     if (!options.supportDynamicLoops) {
       LDBG("--dynamic loop not supported -> BAIL");
       return false;
     }
   } else {
-    int64_t ubImm = upperBoundCst.value();
-    int64_t lbImm = lowerBoundCst.value();
-    int64_t stepImm = stepCst.value();
+    int64_t ubImm = upperBoundCst->getInt();
+    int64_t lbImm = lowerBoundCst->getInt();
+    int64_t stepImm = stepCst->getInt();
     int64_t numIteration = llvm::divideCeilSigned(ubImm - lbImm, stepImm);
-    if (numIteration > maxStage) {
+    if (numIteration > options.numStages - 1) {
       dynamicLoop = false;
-    } else if (!options.supportDynamicLoops) {
-      LDBG("--fewer loop iterations than pipeline stages -> BAIL");
-      return false;
+    } else {
+      LDBG("--fewer loop iterations than pipeline stages");
+      if (!options.supportDynamicLoops) {
+        PERF_WARNING(forOp, "fewer loop iterations than pipeline stages");
+        return false;
+      } else {
+        PERF_WARNING(forOp, "fewer loop iterations than pipeline stages. The "
+                            "loop will be treated as a dynamic loop");
+      }
     }
   }
   peelEpilogue = options.peelEpilogue;
@@ -163,7 +189,6 @@ bool LoopPipelinerInternal::initializeLoopInfo(
   for (Operation &op : forOp.getBody()->without_terminator()) {
     if (!stages.contains(&op)) {
       op.emitOpError("not assigned a pipeline stage");
-      LDBG("--op not assigned a pipeline stage: " << op << " -> BAIL");
       return false;
     }
   }
@@ -180,15 +205,11 @@ bool LoopPipelinerInternal::initializeLoopInfo(
     (void)stageNum;
     if (op == forOp.getBody()->getTerminator()) {
       op->emitError("terminator should not be assigned a stage");
-      LDBG("--terminator should not be assigned stage: " << *op << " -> BAIL");
       return false;
     }
     if (op->getBlock() != forOp.getBody()) {
       op->emitOpError("the owning Block of all operations assigned a stage "
                       "should be the loop body block");
-      LDBG("--the owning Block of all operations assigned a stage "
-           "should be the loop body block: "
-           << *op << " -> BAIL");
       return false;
     }
   }
@@ -226,29 +247,34 @@ static SetVector<Value> getNestedOperands(Operation *op) {
 /// scheduled after its operands (producers) while adjusting for the distance
 /// between producer and consumer.
 bool LoopPipelinerInternal::verifySchedule() {
-  int64_t numCylesPerIter = opOrder.size();
+  int64_t numCyclesPerIter = opOrder.size();
   // Pre-compute the unrolled cycle of each op.
-  DenseMap<Operation *, int64_t> unrolledCyles;
-  for (int64_t cycle = 0; cycle < numCylesPerIter; cycle++) {
+  DenseMap<Operation *, int64_t> unrolledCycles;
+  for (int64_t cycle = 0; cycle < numCyclesPerIter; cycle++) {
     Operation *def = opOrder[cycle];
     auto it = stages.find(def);
     assert(it != stages.end());
     int64_t stage = it->second;
-    unrolledCyles[def] = cycle + stage * numCylesPerIter;
+    unrolledCycles[def] = cycle + stage * numCyclesPerIter;
   }
   for (Operation *consumer : opOrder) {
-    int64_t consumerCycle = unrolledCyles[consumer];
+    int64_t consumerCycle = unrolledCycles[consumer];
     for (Value operand : getNestedOperands(consumer)) {
       auto [producer, distance] = getDefiningOpAndDistance(operand);
       if (!producer)
         continue;
-      auto it = unrolledCyles.find(producer);
+      auto it = unrolledCycles.find(producer);
       // Skip producer coming from outside the loop.
-      if (it == unrolledCyles.end())
+      if (it == unrolledCycles.end())
         continue;
       int64_t producerCycle = it->second;
-      if (consumerCycle < producerCycle - numCylesPerIter * distance) {
+      if (consumerCycle < producerCycle - numCyclesPerIter * distance) {
         consumer->emitError("operation scheduled before its operands");
+        producer->emitError(
+            "The following operation depends on the operation in the "
+            "previous error, which fails the pipelining.\n");
+        LDBG("--operation scheduled before its operands: " << *consumer
+                                                           << " ->  BAIL");
         return false;
       }
     }
@@ -322,9 +348,13 @@ LogicalResult LoopPipelinerInternal::emitPrologue(RewriterBase &rewriter) {
       int predicateIdx = i - stages[op];
       if (predicates[predicateIdx]) {
         OpBuilder::InsertionGuard insertGuard(rewriter);
-        newOp = predicateFn(rewriter, newOp, predicates[predicateIdx]);
-        if (newOp == nullptr)
+        Operation *predicateOp =
+            predicateFn(rewriter, newOp, predicates[predicateIdx]);
+        if (predicateOp == nullptr) {
+          LDBG("--predicateFn returned nullptr -> BAIL");
           return failure();
+        }
+        newOp = predicateOp;
       }
       if (annotateFn)
         annotateFn(newOp, triton::PipeliningOption::PipelinerPart::Prologue, i);
@@ -572,9 +602,13 @@ LogicalResult LoopPipelinerInternal::createKernel(
 
     if (predicates[useStage]) {
       OpBuilder::InsertionGuard insertGuard(rewriter);
-      newOp = predicateFn(rewriter, newOp, predicates[useStage]);
-      if (!newOp)
+      Operation *predicateOp =
+          predicateFn(rewriter, newOp, predicates[useStage]);
+      if (!predicateOp) {
+        LDBG("--predicateFn returned nullptr -> BAIL");
         return failure();
+      }
+      newOp = predicateOp;
       // Remap the results to the new predicated one.
       for (auto values : llvm::zip(op->getResults(), newOp->getResults()))
         mapping.map(std::get<0>(values), std::get<1>(values));
@@ -710,9 +744,13 @@ LoopPipelinerInternal::emitEpilogue(RewriterBase &rewriter,
           });
       if (dynamicLoop) {
         OpBuilder::InsertionGuard insertGuard(rewriter);
-        newOp = predicateFn(rewriter, newOp, predicates[currentVersion]);
-        if (!newOp)
+        Operation *predicateOp =
+            predicateFn(rewriter, newOp, predicates[currentVersion]);
+        if (!predicateOp) {
+          LDBG("--predicateFn returned nullptr -> BAIL");
           return failure();
+        }
+        newOp = predicateOp;
       }
       if (annotateFn)
         annotateFn(newOp, triton::PipeliningOption::PipelinerPart::Epilogue,
@@ -782,15 +820,19 @@ mlir::triton::pipelineForLoop(RewriterBase &rewriter, ForOp forOp,
   if (modifiedIR)
     *modifiedIR = false;
   LoopPipelinerInternal pipeliner;
-  if (!pipeliner.initializeLoopInfo(forOp, options))
+  if (!pipeliner.initializeLoopInfo(forOp, options)) {
+    LDBG("--initializeLoopInfo failed -> BAIL");
     return failure();
+  }
 
   if (modifiedIR)
     *modifiedIR = true;
 
   // 1. Emit prologue.
-  if (failed(pipeliner.emitPrologue(rewriter)))
+  if (failed(pipeliner.emitPrologue(rewriter))) {
+    LDBG("--emitPrologue failed -> BAIL");
     return failure();
+  }
 
   // 2. Track values used across stages. When a value cross stages it will
   // need to be passed as loop iteration arguments.
@@ -809,16 +851,20 @@ mlir::triton::pipelineForLoop(RewriterBase &rewriter, ForOp forOp,
   // Create the kernel block, order ops based on user choice and remap
   // operands.
   if (failed(pipeliner.createKernel(newForOp, crossStageValues, loopArgMap,
-                                    rewriter)))
+                                    rewriter))) {
+    LDBG("--createKernel failed -> BAIL");
     return failure();
+  }
 
   llvm::SmallVector<Value> returnValues =
       newForOp.getResults().take_front(forOp->getNumResults());
   if (options.peelEpilogue) {
     // 4. Emit the epilogue after the new forOp.
     rewriter.setInsertionPointAfter(newForOp);
-    if (failed(pipeliner.emitEpilogue(rewriter, returnValues)))
+    if (failed(pipeliner.emitEpilogue(rewriter, returnValues))) {
+      LDBG("--emitEpilogue failed -> BAIL");
       return failure();
+    }
   }
   // 5. Erase the original loop and replace the uses with the epilogue output.
   if (forOp->getNumResults() > 0)
diff --git a/python/test/unit/test_perf_warning.py b/python/test/unit/test_perf_warning.py
index 8b793dd36..6d16049f4 100644
--- a/python/test/unit/test_perf_warning.py
+++ b/python/test/unit/test_perf_warning.py
@@ -3,6 +3,16 @@ import triton.language as tl
 import os
 import pytest
 import torch
+from contextlib import contextmanager
+
+
+@contextmanager
+def enable_remark_context():
+    try:
+        os.environ['MLIR_ENABLE_REMARK'] = '1'
+        yield
+    finally:
+        os.environ['MLIR_ENABLE_REMARK'] = '0'
 
 
 def is_perf_warning_enabled():
@@ -13,14 +23,12 @@ def is_cuda():
     return triton.runtime.driver.active.get_current_target().backend == "cuda"
 
 
-def test_mma_remark(capfd):
+def test_mma_remark(capfd, fresh_triton_cache):
     if is_cuda():
         capability = torch.cuda.get_device_capability()
         if capability[0] < 9:
             pytest.skip("Requires sm >= 90 to run")
 
-    os.environ['MLIR_ENABLE_REMARK'] = '1'
-
     @triton.jit
     def matmul_kernel(a_ptr, b_ptr, c_ptr, M, N, K, stride_am, stride_ak, stride_bk, stride_bn, stride_cm, stride_cn):
         a_block_ptr = tl.make_block_ptr(base=a_ptr, shape=(M, K), strides=(stride_am, stride_ak), offsets=(0, 0),
@@ -34,21 +42,20 @@ def test_mma_remark(capfd):
         c = tl.dot(a, b)
         tl.store(c_block_ptr, c)
 
-    triton.compile(
-        triton.compiler.ASTSource(
-            fn=matmul_kernel, signature={
-                0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32', 4: 'i32', 5: 'i32', 6: 'i32', 7: 'i32', 8: 'i32', 9:
-                'i32', 10: 'i32', 11: 'i32'
-            }, constants={}))
+    with enable_remark_context():
+        triton.compile(
+            triton.compiler.ASTSource(
+                fn=matmul_kernel, signature={
+                    0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32', 4: 'i32', 5: 'i32', 6: 'i32', 7: 'i32', 8: 'i32', 9:
+                    'i32', 10: 'i32', 11: 'i32'
+                }, constants={}))
     captured = capfd.readouterr()
 
     assert "remark: Warning: can't use MMA V3 for the dot op" in captured.err, "expect MMA V3 remark"
     assert "note: see current operation:" in captured.err
-    os.environ['MLIR_ENABLE_REMARK'] = '0'
 
 
-def test_remark_vectorization(capfd):
-    os.environ["MLIR_ENABLE_REMARK"] = "1"
+def test_remark_vectorization(capfd, fresh_triton_cache):
 
     @triton.jit
     def ldst_vec(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, XBLOCK: tl.constexpr):
@@ -74,10 +81,69 @@ def test_remark_vectorization(capfd):
         tl.store(out_ptr0 + (x4), tmp22, None)
 
     XBLOCK = 1024
-    triton.compile(
-        triton.compiler.ASTSource(fn=ldst_vec, signature={0: '*i64', 1: '*i64', 2: '*fp16', 3: '*fp32', 4: '*fp16'},
-                                  constants={"XBLOCK": XBLOCK}), options={"num_warps": 1})
+    with enable_remark_context():
+        triton.compile(
+            triton.compiler.ASTSource(fn=ldst_vec, signature={0: '*i64', 1: '*i64', 2: '*fp16', 3: '*fp32', 4: '*fp16'},
+                                      constants={"XBLOCK": XBLOCK}), options={"num_warps": 1})
 
     _, err = capfd.readouterr()
+
     assert ("remark: Warning: vectorization fails" in err), "expect vectorization failure remark"
-    os.environ["MLIR_ENABLE_REMARK"] = "0"
+
+
+def test_remark_swp_num_stages_greater_than_loop_iters(capfd, fresh_triton_cache):
+
+    @triton.jit
+    def kernel_pipe_num_stages_gt_loop_iters(in_ptr, out_ptr):
+        SIZE: tl.constexpr = 64
+        in_ptrs = in_ptr + tl.arange(0, SIZE)
+        for i in tl.range(0, 2, num_stages=3):
+            val = tl.load(in_ptrs)
+            in_ptrs += SIZE
+            out_ptrs = out_ptr + (tl.arange(0, SIZE) + i * SIZE)
+            tl.store(out_ptrs, val)
+
+    with enable_remark_context():
+        triton.compile(
+            triton.compiler.ASTSource(fn=kernel_pipe_num_stages_gt_loop_iters, signature={0: '*fp32', 1: '*fp32'},
+                                      constants={}), options={"cluster_dims": (1, 1, 1)})
+
+    _, err = capfd.readouterr()
+    assert ("remark: Warning: fewer loop iterations than pipeline stages. The loop will be treated as a dynamic loop"
+            in err), "expect performance warning remark:" + err
+
+
+def test_remark_swp_op_before_operands(capfd, fresh_triton_cache):
+
+    @triton.jit
+    def kernel_pipe_error(in_ptr, out_ptr):
+        SIZE: tl.constexpr = 64
+        in_ptrs = in_ptr + tl.arange(0, SIZE)
+        val = tl.zeros((SIZE, ), dtype=tl.float32)
+        k = 0
+        for i in tl.range(0, 64, num_stages=3):
+            in_ptrs = in_ptr + tl.arange(0, SIZE) + SIZE * k
+            val = tl.load(in_ptrs)
+            out_ptrs = out_ptr + (tl.arange(0, SIZE) + i * SIZE)
+            tl.store(out_ptrs, val)
+            if tl.max(val) > 0:
+                k += 1
+
+    with enable_remark_context():
+        triton.compile(
+            triton.compiler.ASTSource(fn=kernel_pipe_error, signature={0: '*fp32', 1: '*fp32'}, constants={}),
+            options={"cluster_dims": (1, 1, 1)})
+
+    _, err = capfd.readouterr()
+
+    import re
+    # first match `if tl.max(val) > 0:`, then match `val = tl.load(in_ptrs)``
+    pattern = (r"operation scheduled before its operands.*"
+               r"note: called from\s+"
+               r"if tl.max\(val\) > 0:.*"
+               r"The following operation depends on the operation in the previous error, which fails the pipelining.\s+"
+               r"val = tl.load\(in_ptrs\)")
+    # Use re.DOTALL to make '.' match any character including newline
+    match = re.search(pattern, err, re.DOTALL)
+    # Assert that the pattern is found in the correct order
+    assert match, "Expected performance warning remarks not found or not in the correct order:" + err
